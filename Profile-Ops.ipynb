{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook, let us test the performance of various individual Ops involved in Inference Pipeline and try to optimize them to get the best performance out of our Style Transfer network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from models import *\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = TransformerNet().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Inference Pipeline\n",
    "The following block shows the basic inference pipeline which does style transfer on the frames extracted from the webcam.\n",
    "\n",
    "In broad sense, inference pipeline can be broken down into 4 modules.\n",
    "- Fetch (frames from Webcam)\n",
    "- Preprocess (the frames)\n",
    "- Prediction (The model inference phase)\n",
    "- Post-process + Render (Rendering the final results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to infer = 0.06374223518371581\n",
      "Time taken to infer = 0.06224231505393982\n",
      "Time taken to infer = 0.06326079225540161\n",
      "Time taken to infer = 0.06299156737327576\n",
      "Time taken to infer = 0.06327822160720825\n",
      "Time taken to infer = 0.06356794118881226\n",
      "Time taken to infer = 0.06337778925895692\n",
      "Time taken to infer = 0.06440203619003296\n",
      "Time taken to infer = 0.06361738705635071\n",
      "Time taken to infer = 0.06413892650604248\n",
      "Mean = 0.06346192116737366, StdDev = 0.0005697443838206991\n"
     ]
    }
   ],
   "source": [
    "def test_v1():\n",
    "    model.eval()\n",
    "    \n",
    "    # Setup content transform\n",
    "    content_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.mul(255))\n",
    "    ])\n",
    "    \n",
    "    camera = cv2.VideoCapture(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        counter = 1000\n",
    "        start = time.time()\n",
    "        while counter > 0:\n",
    "            _, frame = camera.read()\n",
    "            content_image = content_transform(frame)\n",
    "            content_image = content_image.unsqueeze(0).cuda()\n",
    "            output = model(content_image).cpu().detach()[0].clamp(0, 255).numpy().transpose(1,2,0).astype(\"uint8\")\n",
    "            counter -= 1\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        print('Time taken to infer =', (end-start)/1000.0)\n",
    "    camera.release()\n",
    "    return (end-start)/1000.0\n",
    "\n",
    "# Run 10 experiments\n",
    "time_v1 = []\n",
    "for i in range(10):\n",
    "    time_v1.append(test_v1())\n",
    "time_v1 = np.asarray(time_v1)\n",
    "print('Mean = {}, StdDev = {}'.format(np.mean(time_v1, axis=0), np.std(time_v1, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "We have seen from above that the model inference takes around 63.5 milliseconds. That is rougly 15.7 FPS.\n",
    "\n",
    "Now let us focus on each individual module and try to optimize them.\n",
    "\n",
    "## Preprocessing (HWC -> CHW -> NCHW)\n",
    "\n",
    "Here is a summary of three tests we are making:\n",
    "- V1: Use PyTorch's `transforms` to convert the image (UInt8) into tensor (Float32) format.\n",
    "- V2: Use OpenCV + NumPy to convert the image (UInt8) into tensor (Float32) format.\n",
    "- V3: Use OpenCV + NumPy to convert the image (UInt8) into tensor (UInt8/Byte) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to pre-process = 0.007729572057723999\n",
      "Time taken to pre-process = 0.007927640914916993\n",
      "Time taken to pre-process = 0.00809889245033264\n",
      "Time taken to pre-process = 0.008704333305358887\n",
      "Time taken to pre-process = 0.009419626951217652\n",
      "Time taken to pre-process = 0.009154453754425048\n",
      "Time taken to pre-process = 0.008751245260238648\n",
      "Time taken to pre-process = 0.008776693105697632\n",
      "Time taken to pre-process = 0.008691324234008788\n",
      "Time taken to pre-process = 0.009496425151824951\n",
      "V1: Mean = 0.008675020718574521, StdDev = 0.0005710206415376447\n",
      "\n",
      "Time taken to pre-process = 0.00466198468208313\n",
      "Time taken to pre-process = 0.004477731704711914\n",
      "Time taken to pre-process = 0.00536241602897644\n",
      "Time taken to pre-process = 0.004512583255767822\n",
      "Time taken to pre-process = 0.0046747827529907224\n",
      "Time taken to pre-process = 0.0046655011177062986\n",
      "Time taken to pre-process = 0.004764933109283448\n",
      "Time taken to pre-process = 0.0051664204597473146\n",
      "Time taken to pre-process = 0.0047572414875030515\n",
      "Time taken to pre-process = 0.004550928115844726\n",
      "V2: Mean = 0.004759452271461487, StdDev = 0.00027175579405898864\n",
      "\n",
      "Time taken to pre-process = 3.0231475830078124e-06\n",
      "Time taken to pre-process = 2.993345260620117e-06\n",
      "Time taken to pre-process = 2.993345260620117e-06\n",
      "Time taken to pre-process = 2.959251403808594e-06\n",
      "Time taken to pre-process = 1.994609832763672e-06\n",
      "Time taken to pre-process = 3.017425537109375e-06\n",
      "Time taken to pre-process = 1.9969940185546874e-06\n",
      "Time taken to pre-process = 1.9989013671875e-06\n",
      "Time taken to pre-process = 2.98762321472168e-06\n",
      "Time taken to pre-process = 2.992391586303711e-06\n",
      "V3: Mean = 2.6957035064697265e-06, StdDev = 4.578061655308803e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimize Pre-processing (HWC -> CHW -> NCHW)\n",
    "content_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.mul(255))\n",
    "])\n",
    "camera = cv2.VideoCapture(0)\n",
    "_, frame = camera.read()\n",
    "camera.release()\n",
    "\n",
    "# V1: Use TorchVision Transforms (Pillow backend)\n",
    "time_preprocess_v1 = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        content_image = content_transform(frame)\n",
    "        content_image = content_image.unsqueeze(0)\n",
    "        counter -= 1\n",
    "    end = time.time()\n",
    "    print('Time taken to pre-process =', (end-start)/1000.0)\n",
    "    time_preprocess_v1.append((end-start)/1000.0)\n",
    "time_preprocess_v1 = np.asarray(time_preprocess_v1)\n",
    "print('V1: Mean = {}, StdDev = {}\\n'.format(np.mean(time_preprocess_v1, axis=0), np.std(time_preprocess_v1, axis=0)))\n",
    "\n",
    "# Use OpenCV and Numpy to transform Image\n",
    "time_preprocess_v2 = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        frame_temp = frame.swapaxes(1, 2).swapaxes(0, 1)\n",
    "        frame_temp = frame_temp[np.newaxis, :, :, :]\n",
    "        content_image = torch.from_numpy(frame_temp).type(torch.FloatTensor)\n",
    "        counter -= 1\n",
    "    end = time.time()\n",
    "    print('Time taken to pre-process =', (end-start)/1000.0)\n",
    "    time_preprocess_v2.append((end-start)/1000.0)\n",
    "time_preprocess_v2 = np.asarray(time_preprocess_v2)\n",
    "print('V2: Mean = {}, StdDev = {}\\n'.format(np.mean(time_preprocess_v2, axis=0), np.std(time_preprocess_v2, axis=0)))\n",
    "\n",
    "# Modify v2 by not converting it to float on CPU\n",
    "time_preprocess_v3 = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        frame_temp = frame.swapaxes(1, 2).swapaxes(0, 1)\n",
    "        frame_temp = frame_temp[np.newaxis, :, :, :]\n",
    "        content_image = torch.from_numpy(frame_temp)\n",
    "        counter -= 1\n",
    "    end = time.time()\n",
    "    print('Time taken to pre-process =', (end-start)/1000.0)\n",
    "    time_preprocess_v3.append((end-start)/1000.0)\n",
    "time_preprocess_v3 = np.asarray(time_preprocess_v3)\n",
    "print('V3: Mean = {}, StdDev = {}\\n'.format(np.mean(time_preprocess_v3, axis=0), np.std(time_preprocess_v3, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above that `V2` is faster than `V1`, which can clearly say that OpenCV+NumPy is faster than using Pillow for image transforms. In `V3`, we are not converting the tensor to Float32 and leaving it as UInt8. Looks like the costly operation is converting UInt8 to Float in CPU. The idea is whether we can push this Op to GPU instead of doing it on CPU.\n",
    "\n",
    "## Data Transfer (CPU -> GPU)\n",
    "\n",
    "Here is a summary of two tests we are applying:\n",
    "- V1: Transfer Float32 Tensor to GPU\n",
    "- V2: Transfer UInt8 Tensor to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to transfer Float= 0.0006362755298614502\n",
      "Time taken to transfer Float= 0.000767960786819458\n",
      "Time taken to transfer Float= 0.0007988643646240234\n",
      "Time taken to transfer Float= 0.0005784521102905274\n",
      "Time taken to transfer Float= 0.0007185821533203126\n",
      "Time taken to transfer Float= 0.0005704751014709473\n",
      "Time taken to transfer Float= 0.000593414545059204\n",
      "Time taken to transfer Float= 0.0005744626522064209\n",
      "Time taken to transfer Float= 0.0005889854431152344\n",
      "Time taken to transfer Float= 0.0005680437088012695\n",
      "V1: Mean = 0.0006395516395568848, StdDev = 8.406322692265474e-05\n",
      "\n",
      "Time taken to transfer UInt8= 0.0011579360961914062\n",
      "Time taken to transfer UInt8= 0.0011855967044830322\n",
      "Time taken to transfer UInt8= 0.0011219978332519531\n",
      "Time taken to transfer UInt8= 0.0011370019912719726\n",
      "Time taken to transfer UInt8= 0.0012177438735961913\n",
      "Time taken to transfer UInt8= 0.0011928267478942872\n",
      "Time taken to transfer UInt8= 0.0011908178329467774\n",
      "Time taken to transfer UInt8= 0.0010940773487091065\n",
      "Time taken to transfer UInt8= 0.0011707301139831543\n",
      "Time taken to transfer UInt8= 0.0013493940830230713\n",
      "V2: Mean = 0.0011818122625350954, StdDev = 6.600569310258787e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "_, frame = camera.read()\n",
    "camera.release()\n",
    "frame = frame.swapaxes(1, 2).swapaxes(0, 1)\n",
    "frame = frame[np.newaxis, :, :, :]\n",
    "content_image = torch.from_numpy(frame)\n",
    "\n",
    "# Data Transfer tests\n",
    "# 1: Transfer Float to GPU\n",
    "content_image_float = content_image.type(torch.FloatTensor)\n",
    "time_f_trans = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        temp = content_image_float.cuda()\n",
    "        counter -= 1\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print('Time taken to transfer Float=', (end-start)/1000.0)\n",
    "    time_f_trans.append((end-start)/1000.0)\n",
    "print('V1: Mean = {}, StdDev = {}\\n'.format(np.mean(time_f_trans, axis=0), np.std(time_f_trans, axis=0)))\n",
    "\n",
    "# 2: Transfer UInt8 to GPU\n",
    "time_i8_trans = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        temp = content_image.cuda()\n",
    "        counter -= 1\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print('Time taken to transfer UInt8=', (end-start)/1000.0)\n",
    "    time_i8_trans.append((end-start)/1000.0)\n",
    "print('V2: Mean = {}, StdDev = {}\\n'.format(np.mean(time_i8_trans, axis=0), np.std(time_i8_trans, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we can observe that passing a Float32 tensor is way faster (2x) than passing an UInt8 tensor. Now, let us do the following fused tests:\n",
    "\n",
    "- Convert UInt8 -> Float32 on CPU, and pass Float32 to GPU\n",
    "- Pass UInt8 to GPU, and convert it to Float32 on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to transfer Float = 0.0051630535125732424\n",
      "Time taken to transfer Float = 0.005124115467071534\n",
      "Time taken to transfer Float = 0.0052873239517211915\n",
      "Time taken to transfer Float = 0.005293906688690186\n",
      "Time taken to transfer Float = 0.0050066132545471195\n",
      "Time taken to transfer Float = 0.00499297571182251\n",
      "Time taken to transfer Float = 0.004989104509353638\n",
      "Time taken to transfer Float = 0.005008767604827881\n",
      "Time taken to transfer Float = 0.0050498549938201905\n",
      "Time taken to transfer Float = 0.004984730005264283\n",
      "V1: Mean = 0.005090044569969178, StdDev = 0.0001152624820694124\n",
      "\n",
      "Time taken to transfer UInt8 = 0.0012316856384277344\n",
      "Time taken to transfer UInt8 = 0.001218740463256836\n",
      "Time taken to transfer UInt8 = 0.0013094983100891114\n",
      "Time taken to transfer UInt8 = 0.0011509225368499757\n",
      "Time taken to transfer UInt8 = 0.0011757762432098389\n",
      "Time taken to transfer UInt8 = 0.0012422752380371093\n",
      "Time taken to transfer UInt8 = 0.0014308736324310303\n",
      "Time taken to transfer UInt8 = 0.0014117023944854737\n",
      "Time taken to transfer UInt8 = 0.0014496314525604247\n",
      "Time taken to transfer UInt8 = 0.0013518471717834473\n",
      "V2: Mean = 0.0012972953081130981, StdDev = 0.00010342042445861657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fused Data Transfer tests\n",
    "# 1: Convert to Float & Transfer to GPU\n",
    "time_f_trans = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        content_image_float = content_image.type(torch.FloatTensor)\n",
    "        temp = content_image_float.cuda()\n",
    "        counter -= 1\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print('Time taken to transfer Float =', (end-start)/1000.0)\n",
    "    time_f_trans.append((end-start)/1000.0)\n",
    "print('V1: Mean = {}, StdDev = {}\\n'.format(np.mean(time_f_trans, axis=0), np.std(time_f_trans, axis=0)))\n",
    "\n",
    "# 2: Transfer UInt8 to GPU & Convert to Float\n",
    "time_i8_trans = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        temp = content_image.cuda()\n",
    "        temp = temp.type(torch.cuda.FloatTensor)\n",
    "        counter -= 1\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print('Time taken to transfer UInt8 =', (end-start)/1000.0)\n",
    "    time_i8_trans.append((end-start)/1000.0)\n",
    "print('V2: Mean = {}, StdDev = {}\\n'.format(np.mean(time_i8_trans, axis=0), np.std(time_i8_trans, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we can see that using Preprocessing V3 + Data Transfer (Fused) V2 can give us the most optimal performance before inference.\n",
    "\n",
    "## Postprocessing (GPU->CPU->Image)\n",
    "\n",
    "Now let us optimize the post-processing. Here is the summary of tests.\n",
    "- V1: Do complete post-processing on CPU.\n",
    "- V2: Do `clamp()` on GPU and rest on CPU.\n",
    "- V3: Do `clamp()` and `type(torch.cuda.ByteTensor)` on GPU and rest on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to transfer to CPU (v1) = 0.004254332065582275\n",
      "Time taken to transfer to CPU (v1) = 0.004119851589202881\n",
      "Time taken to transfer to CPU (v1) = 0.004068934440612793\n",
      "Time taken to transfer to CPU (v1) = 0.004113720893859863\n",
      "Time taken to transfer to CPU (v1) = 0.004333008766174316\n",
      "Time taken to transfer to CPU (v1) = 0.003925081729888916\n",
      "Time taken to transfer to CPU (v1) = 0.003935510158538818\n",
      "Time taken to transfer to CPU (v1) = 0.004238506555557251\n",
      "Time taken to transfer to CPU (v1) = 0.004195333957672119\n",
      "Time taken to transfer to CPU (v1) = 0.004248223066329956\n",
      "V1: Mean = 0.004143250322341919, StdDev = 0.00012994191057122414\n",
      "\n",
      "Time taken to transfer to CPU (v2) = 0.0025672900676727297\n",
      "Time taken to transfer to CPU (v2) = 0.002452530860900879\n",
      "Time taken to transfer to CPU (v2) = 0.0024302475452423096\n",
      "Time taken to transfer to CPU (v2) = 0.0027535762786865233\n",
      "Time taken to transfer to CPU (v2) = 0.0024895095825195313\n",
      "Time taken to transfer to CPU (v2) = 0.0024485158920288085\n",
      "Time taken to transfer to CPU (v2) = 0.002428553581237793\n",
      "Time taken to transfer to CPU (v2) = 0.0024239678382873536\n",
      "Time taken to transfer to CPU (v2) = 0.002480652093887329\n",
      "Time taken to transfer to CPU (v2) = 0.002482649803161621\n",
      "V2: Mean = 0.0024957493543624875, StdDev = 9.491493030630422e-05\n",
      "\n",
      "Time taken to transfer to CPU (v3) = 0.00041991996765136717\n",
      "Time taken to transfer to CPU (v3) = 0.00040691089630126955\n",
      "Time taken to transfer to CPU (v3) = 0.0004193201065063477\n",
      "Time taken to transfer to CPU (v3) = 0.0004189131259918213\n",
      "Time taken to transfer to CPU (v3) = 0.00037499594688415527\n",
      "Time taken to transfer to CPU (v3) = 0.00037503385543823244\n",
      "Time taken to transfer to CPU (v3) = 0.0004079086780548096\n",
      "Time taken to transfer to CPU (v3) = 0.0004892253875732422\n",
      "Time taken to transfer to CPU (v3) = 0.0003759956359863281\n",
      "Time taken to transfer to CPU (v3) = 0.0004108998775482178\n",
      "V2: Mean = 0.00040991234779357905, StdDev = 3.187512651934858e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "_, frame = camera.read()\n",
    "camera.release()\n",
    "frame = frame.swapaxes(1, 2).swapaxes(0, 1)\n",
    "frame = frame[np.newaxis, :, :, :]\n",
    "content_image = torch.from_numpy(frame)\n",
    "content_image = content_image.type(torch.cuda.FloatTensor)\n",
    "content_image = model(content_image)\n",
    "\n",
    "# 1: Post-process v1\n",
    "time_f_trans = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        temp = content_image.cpu().detach()[0].clamp(0, 255).numpy().transpose(1,2,0).astype(\"uint8\")\n",
    "        counter -= 1\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print('Time taken to transfer to CPU (v1) =', (end-start)/1000.0)\n",
    "    time_f_trans.append((end-start)/1000.0)\n",
    "print('V1: Mean = {}, StdDev = {}\\n'.format(np.mean(time_f_trans, axis=0), np.std(time_f_trans, axis=0)))\n",
    "\n",
    "\n",
    "# 2: Post-process v2\n",
    "time_f_trans = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        temp = content_image.clamp(0, 255).cpu().detach()[0].numpy().transpose(1,2,0).astype(\"uint8\")\n",
    "        counter -= 1\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print('Time taken to transfer to CPU (v2) =', (end-start)/1000.0)\n",
    "    time_f_trans.append((end-start)/1000.0)\n",
    "print('V2: Mean = {}, StdDev = {}\\n'.format(np.mean(time_f_trans, axis=0), np.std(time_f_trans, axis=0)))\n",
    "\n",
    "\n",
    "# 3: Post-process v3\n",
    "time_f_trans = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        temp = content_image.clamp(0, 255).type(torch.cuda.ByteTensor).cpu().detach()[0].numpy().transpose(1,2,0)\n",
    "        counter -= 1\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print('Time taken to transfer to CPU (v3) =', (end-start)/1000.0)\n",
    "    time_f_trans.append((end-start)/1000.0)\n",
    "print('V3: Mean = {}, StdDev = {}\\n'.format(np.mean(time_f_trans, axis=0), np.std(time_f_trans, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we can see that Postprocessing V3 ideally takes less than 1 millisecond.\n",
    "\n",
    "Finally let us try converting the serialized camera buffer to asynchronous camera buffer. The idea for this approach has been taken with inspiration from - http://blog.blitzblit.com/2017/12/24/asynchronous-video-capture-in-python-with-opencv/\n",
    "\n",
    "Here are the tests between serialized and asynchronous frame buffer. The underlying idea is don't wait for extracting the next frame buffer from camera while current frame is being processed through inference pipeline.\n",
    "\n",
    "# Async Video Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for camera frame buffer = 0.03359849333763123\n",
      "Time taken for camera frame buffer = 0.03401651501655579\n",
      "Time taken for camera frame buffer = 0.03358498334884644\n",
      "Time taken for camera frame buffer = 0.033881309747695924\n",
      "Time taken for camera frame buffer = 0.0338202064037323\n",
      "Time taken for camera frame buffer = 0.033706856966018675\n",
      "Time taken for camera frame buffer = 0.033889217138290406\n",
      "Time taken for camera frame buffer = 0.0338252854347229\n",
      "Time taken for camera frame buffer = 0.033578208684921264\n",
      "Time taken for camera frame buffer = 0.033848626375198365\n",
      "V1: Mean = 0.03377497024536133, StdDev = 0.0001425837027357211\n",
      "\n",
      "Time taken for camera frame buffer = 3.291463851928711e-05\n",
      "Time taken for camera frame buffer = 3.2912015914916994e-05\n",
      "Time taken for camera frame buffer = 3.490662574768066e-05\n",
      "Time taken for camera frame buffer = 3.291177749633789e-05\n",
      "Time taken for camera frame buffer = 3.390955924987793e-05\n",
      "Time taken for camera frame buffer = 3.291153907775879e-05\n",
      "Time taken for camera frame buffer = 3.490757942199707e-05\n",
      "Time taken for camera frame buffer = 3.394126892089844e-05\n",
      "Time taken for camera frame buffer = 3.3876895904541016e-05\n",
      "Time taken for camera frame buffer = 3.295135498046875e-05\n",
      "V2: Mean = 3.3614325523376463e-05, StdDev = 7.755873134970193e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from videocapture_async import VideoCaptureAsync\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "time_sync_camera = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        ret, frame = camera.read()\n",
    "        counter -= 1\n",
    "    end = time.time()\n",
    "    print('Time taken for camera frame buffer =', (end-start)/1000.0)\n",
    "    time_sync_camera.append((end-start)/1000.0)\n",
    "camera.release()\n",
    "print('V1: Mean = {}, StdDev = {}\\n'.format(np.mean(time_sync_camera, axis=0), np.std(time_sync_camera, axis=0)))\n",
    "\n",
    "camera = VideoCaptureAsync(0)\n",
    "camera.start()\n",
    "time_async_camera = []\n",
    "for i in range(10):\n",
    "    counter = 1000\n",
    "    start = time.time()\n",
    "    while counter > 0:\n",
    "        ret, frame = camera.read()\n",
    "        counter -= 1\n",
    "    end = time.time()\n",
    "    print('Time taken for camera frame buffer =', (end-start)/1000.0)\n",
    "    time_async_camera.append((end-start)/1000.0)\n",
    "camera.stop()\n",
    "print('V2: Mean = {}, StdDev = {}\\n'.format(np.mean(time_async_camera, axis=0), np.std(time_async_camera, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting excited by seeing the above numbers, please be advised that we can't increase the framerate of our camera. The whole idea of AsyncVideoCapture is to run the camera frame extraction on a separate thread and use those frames whenever the inference pipeline is ready for the next frame. \n",
    "\n",
    "Now let us keep all of the above together and run the final inference pipeline.\n",
    "\n",
    "## Optimized Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to infer = 0.046797704935073854\n",
      "Time taken to infer = 0.046382086038589475\n",
      "Time taken to infer = 0.04615999031066895\n",
      "Time taken to infer = 0.046471667289733884\n",
      "Time taken to infer = 0.04696861958503723\n",
      "Time taken to infer = 0.04725742411613464\n",
      "Time taken to infer = 0.047647882223129275\n",
      "Time taken to infer = 0.05035635542869568\n",
      "Time taken to infer = 0.0499716694355011\n",
      "Time taken to infer = 0.049298920392990116\n",
      "Mean = 0.04773123197555541, StdDev = 0.0014808264557047176\n"
     ]
    }
   ],
   "source": [
    "# Optimized Pre-processing + Post-Processing + Camera\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from models import *\n",
    "import time\n",
    "from videocapture_async import VideoCaptureAsync\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "model = TransformerNet().cuda()\n",
    "\n",
    "def test_final():\n",
    "    model.eval()\n",
    "    \n",
    "    camera = VideoCaptureAsync(0)\n",
    "    camera.start()\n",
    "    with torch.no_grad():\n",
    "        counter = 1000\n",
    "        start = time.time()\n",
    "        while counter > 0:\n",
    "            _, frame = camera.read()\n",
    "            # Preprocess the frame\n",
    "            frame = frame.swapaxes(1, 2).swapaxes(0, 1)\n",
    "            frame = frame[np.newaxis, :, :, :]\n",
    "            content_image = torch.from_numpy(frame)\n",
    "            content_image = content_image.cuda()\n",
    "            content_image = content_image.type(torch.cuda.FloatTensor)\n",
    "            # Inference\n",
    "            output = model(content_image).clamp(0, 255).type(torch.cuda.ByteTensor).cpu().detach()[0].numpy().transpose(1,2,0)\n",
    "            counter -= 1\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        print('Time taken to infer =', (end-start)/1000.0)\n",
    "    camera.stop()\n",
    "    return (end-start)/1000.0\n",
    "\n",
    "# Run 10 experiments\n",
    "time_final = []\n",
    "for i in range(10):\n",
    "    time_final.append(test_final())\n",
    "time_final = np.asarray(time_final)\n",
    "print('Mean = {}, StdDev = {}'.format(np.mean(time_final, axis=0), np.std(time_final, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that, by optimizing the Camera Frame Buffer (Async), Preprocessing and postprocessing we can easily increase speed-ups in inference (15.7 FPS -> 21.3 FPS). Here, we have reached the bottleneck of our inference pipeline, i.e., the time taken to do per frame inference. Further speed-ups can be achieved by using [CUDA Streams](https://devblogs.nvidia.com/gpu-pro-tip-cuda-7-streams-simplify-concurrency/) effectively or by modifying model architecture (Playing with different layer combinations, layer fusions etc.)\n",
    "\n",
    "Here is a sneak peak of most optimal performance you can achieve by playing with model architectures:\n",
    "\n",
    "## Changes in Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to infer = 0.021966790199279784\n",
      "Time taken to infer = 0.020345489740371703\n",
      "Time taken to infer = 0.020589972019195556\n",
      "Time taken to infer = 0.020874754428863527\n",
      "Time taken to infer = 0.020950890302658082\n",
      "Time taken to infer = 0.021357654809951783\n",
      "Time taken to infer = 0.021392205238342284\n",
      "Time taken to infer = 0.021567578077316286\n",
      "Time taken to infer = 0.021640504360198976\n",
      "Time taken to infer = 0.02186718463897705\n",
      "Mean = 0.021255302381515503, StdDev = 0.0005161043391833319\n"
     ]
    }
   ],
   "source": [
    "# Optimized Pre-processing + Post-Processing + Camera\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from models import *\n",
    "from models.private import *\n",
    "import time\n",
    "from videocapture_async import VideoCaptureAsync\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "model = TransformerNet_v3().cuda()\n",
    "\n",
    "def test_final():\n",
    "    model.eval()\n",
    "    \n",
    "    camera = VideoCaptureAsync(0)\n",
    "    camera.start()\n",
    "    with torch.no_grad():\n",
    "        counter = 1000\n",
    "        start = time.time()\n",
    "        while counter > 0:\n",
    "            _, frame = camera.read()\n",
    "            # Preprocess the frame\n",
    "            frame = frame.swapaxes(1, 2).swapaxes(0, 1)\n",
    "            frame = frame[np.newaxis, :, :, :]\n",
    "            content_image = torch.from_numpy(frame)\n",
    "            content_image = content_image.cuda()\n",
    "            content_image = content_image.type(torch.cuda.FloatTensor)\n",
    "            # Inference\n",
    "            output = model(content_image).clamp(0, 255).type(torch.cuda.ByteTensor).cpu().detach()[0].numpy().transpose(1,2,0)\n",
    "            counter -= 1\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        print('Time taken to infer =', (end-start)/1000.0)\n",
    "    camera.stop()\n",
    "    return (end-start)/1000.0\n",
    "\n",
    "# Run 10 experiments\n",
    "time_final = []\n",
    "for i in range(10):\n",
    "    time_final.append(test_final())\n",
    "time_final = np.asarray(time_final)\n",
    "print('Mean = {}, StdDev = {}'.format(np.mean(time_final, axis=0), np.std(time_final, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that by making certain architectural changes (keeping CuDNN optimizations into consideration), we could achieve a performane of 47 FPS! \n",
    "\n",
    "Happy coding and you can find the summary of my findings at my blog- \n",
    "# [Style Transfer -PyTorch]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
